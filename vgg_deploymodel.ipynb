{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "ws = Workspace(subscription_id='401a2f63-c029-433e-9087-c839197089fd', resource_group='pix2para_resourcegroup', workspace_name = 'pix2para', auth=cli_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vgg_test'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pix2para': [Workspace.create(name='pix2para', subscription_id='401a2f63-c029-433e-9087-c839197089fd', resource_group='pix2para_resourcegroup')]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.list(subscription_id = '401a2f63-c029-433e-9087-c839197089fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target: cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"creating new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"vggtest\")\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/vgg.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import joblib\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model = VGG19()\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/vgg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "model = VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model = VGG19()\n",
    "\n",
    "def run(image_bytes):\n",
    "    #data = np.array(image)\n",
    "    # make prediction\n",
    "    image_bytes = json.loads(image_bytes)['data']\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.resize((224,224),Image.ANTIALIAS)\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    yhat = model.predict(image)\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0]\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json \n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "from numpy import array\n",
    "\n",
    "def run(image_bytes):\n",
    "\n",
    "    image_bytes = json.loads(image_bytes)['data'][0]\n",
    "    image_bytes = image_bytes.encode('utf-8')\n",
    "    encode_len = len(image_bytes)\n",
    "    print(encode_len)\n",
    "    \n",
    "    image = Image.frombytes('RGBA', (1315,640), image_bytes, 'raw')\n",
    "    \n",
    "    image = image.resize((224,224),Image.ANTIALIAS)    \n",
    "    image = img_to_array(image)\n",
    "    image = image[:,:,0:3]\n",
    "    print(image.shape)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    model = VGG19()\n",
    "    yhat = model.predict(image)\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(130, 130, 130, 255), (130, 130, 130, 255), (104, 104, 104, 255), (104, 104, 104, 255), (112, 116, 106, 255), (112, 116, 106, 255), (90, 94, 82, 255), (90, 95, 82, 255), (90, 95, 82, 255), (90, 95, 82, 255), (89, 94, 81, 255), (89, 94, 81, 255), (88, 92, 79, 255), (87, 91, 78, 255), (87, 91, 78, 255), (86, 90, 77, 255), (86, 88, 76, 255), (85, 87, 75, 255), (85, 87, 75, 255), (85, 87, 75, 255), (88, 89, 77, 255), (90, 90, 78, 255), (80, 79, 68, 255), (70, 69, 57, 255), (52, 51, 42, 255), (35, 32, 26, 255), (32, 29, 23, 255), (31, 27, 21, 255), (36, 32, 27, 255), (42, 37, 34, 255), (47, 42, 39, 255), (51, 47, 43, 255), (51, 47, 43, 255), (49, 47, 41, 255), (47, 46, 40, 255), (46, 45, 38, 255), (46, 45, 38, 255), (45, 45, 38, 255), (44, 45, 38, 255), (44, 44, 37, 255), (44, 44, 37, 255), (44, 45, 38, 255), (44, 45, 38, 255), (43, 44, 37, 255), (43, 44, 37, 255), (44, 45, 38, 255), (44, 45, 38, 255), (45, 46, 39, 255), (44, 46, 38, 255), (44, 45, 37, 255), (43, 45, 35, 255), (42, 44, 35, 255), (42, 44, 35, 255), (43, 45, 36, 255), (44, 46, 36, 255), (44, 46, 37, 255), (44, 46, 37, 255), (44, 46, 37, 255), (44, 45, 38, 255), (45, 46, 39, 255), (45, 47, 39, 255), (45, 47, 39, 255), (45, 47, 39, 255), (45, 46, 39, 255), (44, 45, 38, 255), (44, 46, 38, 255), (45, 47, 37, 255), (45, 47, 37, 255), (45, 47, 37, 255), (45, 47, 37, 255), (45, 47, 37, 255), (45, 47, 37, 255), (44, 46, 37, 255), (44, 46, 37, 255), (44, 46, 37, 255), (44, 46, 37, 255), (45, 47, 37, 255), (46, 47, 38, 255), (47, 48, 39, 255), (47, 48, 40, 255), (48, 49, 40, 255), (48, 49, 40, 255), (48, 49, 40, 255), (48, 49, 40, 255), (48, 49, 40, 255), (47, 49, 40, 255), (47, 50, 40, 255), (46, 50, 40, 255), (47, 51, 41, 255), (48, 52, 42, 255), (48, 52, 42, 255), (48, 52, 42, 255), (48, 51, 41, 255), (48, 51, 41, 255), (47, 51, 41, 255), (47, 51, 41, 255), (47, 51, 41, 255), (47, 51, 41, 255), (47, 52, 40, 255), (47, 52, 39, 255)]\n",
      "(840960, 4)\n",
      "9969101\n",
      "9969101\n",
      "[130, 130, 130, 255, 130, 130, 130, 255, 104, 104]\n",
      "(224, 224, 3)\n",
      "('n09421951', 'sandbar', 0.06210812)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json \n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "from numpy import array\n",
    "\n",
    "def run(image_bytes):\n",
    "    #data = np.array(image)\n",
    "    # make prediction\n",
    "    image_bytes = json.loads(image_bytes)['data'][0]\n",
    "    #print(image_bytes)\n",
    "    image_bytes = image_bytes.encode('utf-8')\n",
    "    encode_len = len(image_bytes)\n",
    "    print(encode_len)\n",
    "    \n",
    "    image = Image.frombytes('RGBA', (1315,640), image_bytes, 'raw')\n",
    "    \n",
    "    image = image.resize((224,224),Image.ANTIALIAS)\n",
    "    pilimg = list(Image.open(image_path, 'r').getdata())\n",
    "    pix_val_flat = [x for sets in pilimg for x in sets]\n",
    "    print(pix_val_flat[0:10])\n",
    "    image.show()\n",
    "    \n",
    "    image = img_to_array(image)\n",
    "    image = image[:,:,0:3]\n",
    "    print(image.shape)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    model = VGG19()\n",
    "    yhat = model.predict(image)\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0]\n",
    "    return label\n",
    "\n",
    "image_path = '/Users/audreycui01/New Unity Project/assets/screenshot.png'\n",
    "image = Image.open(image_path, 'r')\n",
    "#image.show()\n",
    "pilimg = list(image.getdata())\n",
    "#pix_val_flat = [x for sets in pilimg for x in sets]\n",
    "print(pilimg[0:100])\n",
    "print(array(pilimg).shape)\n",
    "#image_bytes = base64.b64encode(pix_val_flat)\n",
    "image_bytes = bytearray(pix_val_flat)\n",
    "image_bytes = str(image_bytes)\n",
    "#image_bytes = image_bytes.decode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "with open(image_path, \"rb\") as imageFile:\n",
    "    image_bytes = base64.b64encode(imageFile.read())\n",
    "    image_bytes = image_bytes.decode('utf-8')\n",
    "'''\n",
    "\n",
    "decode_len = len(image_bytes)\n",
    "print(decode_len)\n",
    "data = {\"data\": [image_bytes]}\n",
    "input_data = json.dumps(data)\n",
    "#print(input_data)\n",
    "label = run(input_data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = \"vggtest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model vggtest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = Model.register(model_path=\"outputs/vgg.pkl\",\n",
    "                        model_name=model_name,\n",
    "                        description=\"vgg test\",\n",
    "                        workspace=ws)\n",
    "#model.download(target_dir=os.getcwd(), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"scikit-learn==0.22.1\")\n",
    "myenv.add_pip_package(\"keras.applications\")\n",
    "myenv.add_pip_package(\"keras.preprocessing\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"keras\")\n",
    "myenv.add_pip_package(\"tensorflow\")\n",
    "myenv.add_pip_package(\"numpy\")\n",
    "myenv.add_pip_package(\"pillow\")\n",
    "\n",
    "\n",
    "with open(\"my_vgg_env.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=8, \n",
    "                                               description='vggtest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running............................................................................."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"my_vgg_env\", file_path=\"my_vgg_env.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name='vggtest', \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-03-08T19:31:00,991622920+00:00 - nginx/run \n",
      "2020-03-08T19:31:00,991706421+00:00 - rsyslog/run \n",
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2020-03-08T19:31:00,992392823+00:00 - iot-server/run \n",
      "2020-03-08T19:31:00,997438337+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-03-08T19:31:01,273681139+00:00 - iot-server/finish 1 0\n",
      "2020-03-08T19:31:01,276388947+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "2020-03-08 19:31:02.668232: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib:/azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib:\n",
      "2020-03-08 19:31:02.668380: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib:/azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib:\n",
      "2020-03-08 19:31:02.668402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "User's init function failed\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/main.py\", line 44, in init\n",
      "    driver_module.init()\n",
      "AttributeError: module 'service_driver' has no attribute 'init'\n",
      "\n",
      "Using TensorFlow backend.\n",
      "Worker exiting (pid: 40)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "/bin/bash: /azureml-envs/azureml_324f55ab119cb8c9bb8f3505406b38c5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-03-08T19:31:03,987285813+00:00 - gunicorn/finish 3 0\n",
      "2020-03-08T19:31:03,988441816+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://44ebd92f-f3e4-4524-a50a-b3569a653cd2.westus.azurecontainer.io/score\n",
      "Healthy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received bad response from Model Management Service:\n",
      "Response Code: 409\n",
      "Headers: {'Date': 'Mon, 09 Mar 2020 03:16:41 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '459980a12afe41fa90aa43117a4a5f25', 'x-ms-client-session-id': '', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n",
      "Content: b'{\"code\":\"Conflict\",\"statusCode\":409,\"message\":\"Conflict\",\"details\":[{\"code\":\"ConflictOfOperation\",\"message\":\"Conflict of operation, another operation on same entity is already running\"}]}'\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 409\nHeaders: {'Date': 'Mon, 09 Mar 2020 03:16:41 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '459980a12afe41fa90aa43117a4a5f25', 'x-ms-client-session-id': '', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"Conflict\",\"statusCode\":409,\"message\":\"Conflict\",\"details\":[{\"code\":\"ConflictOfOperation\",\"message\":\"Conflict of operation, another operation on same entity is already running\"}]}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 409\\nHeaders: {'Date': 'Mon, 09 Mar 2020 03:16:41 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '459980a12afe41fa90aa43117a4a5f25', 'x-ms-client-session-id': '', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"Conflict\\\",\\\"statusCode\\\":409,\\\"message\\\":\\\"Conflict\\\",\\\"details\\\":[{\\\"code\\\":\\\"ConflictOfOperation\\\",\\\"message\\\":\\\"Conflict of operation, another operation on same entity is already running\\\"}]}'\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5a0d8f4dfd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmyenv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_conda_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"my_vgg_env\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"my_vgg_env.yml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/azureml/core/webservice/aci.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, image, tags, properties, description, auth_enabled, ssl_enabled, ssl_cert_pem_file, ssl_key_pem_file, ssl_cname, enable_app_insights, models, inference_config)\u001b[0m\n\u001b[1;32m    479\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     def _validate_update(self, image, tags, properties, description, auth_enabled, ssl_enabled, ssl_cert_pem_file,\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 409\nHeaders: {'Date': 'Mon, 09 Mar 2020 03:16:41 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '459980a12afe41fa90aa43117a4a5f25', 'x-ms-client-session-id': '', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'{\"code\":\"Conflict\",\"statusCode\":409,\"message\":\"Conflict\",\"details\":[{\"code\":\"ConflictOfOperation\",\"message\":\"Conflict of operation, another operation on same entity is already running\"}]}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 409\\nHeaders: {'Date': 'Mon, 09 Mar 2020 03:16:41 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '459980a12afe41fa90aa43117a4a5f25', 'x-ms-client-session-id': '', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"Conflict\\\",\\\"statusCode\\\":409,\\\"message\\\":\\\"Conflict\\\",\\\"details\\\":[{\\\"code\\\":\\\"ConflictOfOperation\\\",\\\"message\\\":\\\"Conflict of operation, another operation on same entity is already running\\\"}]}'\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "service = AciWebservice(ws, 'vggtest')\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "myenv = Environment.from_conda_specification(name=\"my_vgg_env\", file_path=\"my_vgg_env.yml\")\n",
    "\n",
    "service.update(inference_config = inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
